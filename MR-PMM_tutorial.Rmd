---
title: "Multi-Response Phylogenetic Mixed Models"
author: "Ben Halliwell & Luke Yates"
header-includes:
  - \usepackage{mathtools}
  - \usepackage{multirow}
date: "2023"
bibliography: bib_MR-PMM.bib
link-citations: true
output: 
  html_document:
    number_sections: false
    toc: true 
    toc_float:
      collapsed: false
      smooth_scroll: false
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}

knitr::opts_chunk$set(echo = TRUE, dev="png", dpi=96)

library(rstan);library(brms);library(dplyr);library(tidyverse);library(tidybayes)
library(ggplot2);library(ggpubr);library(knitr);library(MCMCglmm);library(bayesplot)
library(geiger);library(ape);library(phytools);library(caper);library(parallel);library(coda)
library(ggtree)

m.1 <- readRDS("m.1.rds");b.1 <- readRDS("b.1.rds")
m.2 <- readRDS("m.2.rds");b.2 <- readRDS("b.2.rds")
m.3 <- readRDS("m.3.rds");b.3 <- readRDS("b.3.rds")
b.euc <- readRDS("b.euc.rds")

```

This tutorial is associated with the article "Multi-Response Phylogenetic Mixed Models: Concepts and Application"

EcoEvoRxiv preprint https://doi.org/10.1101/2022.12.13.520338

by

Ben Halliwell, Luke A. Yates & Barbara R. Holland

\

**N.B. This tutorial is a live document that will continue to be updated as the authors incorporate new content, techniques and visualisations of the data**

\

# Introduction

<!-- PMM is motivated by the observation that closely related species tend to resemble each other phenotypically (a phenomenon known as phylogenetic signal), meaning species often do not represent independent data points with respect to evolutionary hypotheses. Instead, we must test for non-independence  and adjust our analyses accordingly. A central assumption of PMM therefore, is that we can combine a molecular phylogeny with a model of evolution (nominally, Brownian Motion (BM)) to generate a covariance matrix that defines the expected phenotypic similarity among taxa. The strength of this signal is optimised from the data during model fit, scaling the magnitude of effects to produce a phylogenetically informed regression. For univariate (UV) cases, this approach only estimates phylogenetic signal in the response variable, while any predictor variables in the model are assumed not to display phylogenetic signal. This assumption is commonly violated in analyses of real world data sets (where predictor variables often represent species traits that are themselves subject to phylogenetic effects), leading to identifiability issues. This problem is effectively addressed by moving offending predictor variables to the LHS of the model equation in multi-response (MR) implementations. This way, phylogenetic signal is simultaneously evaluated for all relevant traits, allowing (co)variances between response variables to be partitioned across multiple levels in the model hierarchy (e.g. phylogenetic and independent). This partitioning is important because phenotypic covariances (i.e., covariance on the level of traits measured), Cov(y1,y2), represent the sum of covariances on hierarchically lower levels, which need not align in magnitude or even direction. Thus, for comparative analyses of species traits with sufficient replication, MR-PMM should be preferred, as it offers more informative outputs with respect to evolutionary hypotheses. -->

In this tutorial we will cover how to implement multi-response (MR) phylogenetic mixed models (PMM) in two popular R packages, MCMCglmm and brms. While frequentist implementations of the PMM are available (e.g., pglmm() in the "phyr" package), we advocate for a Bayesian approach due to 1) greater flexibility in fitting non-Gaussian response traits 2) suitability for estimating variance components associated with structured random effects; 3) the ability to sample conditional multivariate distributions, avoiding intractable integration problems faced by frequentist techniques.

Throughout this tutorial, we explore a low dimensional example (tree with only 5 taxa) in order to show full workings of the matrix manipulations that underlie the covariance structures specified. This is for the sake of exposition only; analyses of the form presented will typically require much higher sample sizes to produce reliable estimates of, for example, phylogenetic correlations [@housworth2004phylogenetic]. Thus, while the mathematical workings presented follow a 5 taxa example, model outputs are based on analyses of data simulated for 250 taxa.

\

# Model 1 - Single-Response Gaussian

\

## Model Explanation

For the case of a single Gaussian trait, our response variable, $\mathbf{y}$, is modeled directly as a linear combination of the fixed effects $\boldsymbol{\mu}$, a phylogenetic random effect, $\mathbf{b}$, and residual variance, $\mathbf{e}$.

\

\begin{eqnarray}
\mathbf{y} &=& \boldsymbol{\mu} + \mathbf{b} + \mathbf{e}\\[2mm]
\end{eqnarray}\

\

where $\boldsymbol{\mu}$ represents,

\

```{=tex}
\begin{eqnarray}
\boldsymbol{\mu}  = \beta_0 + \beta_1\boldsymbol{X_1} + \ldots + \beta_{k}\boldsymbol{X_{k}}
\end{eqnarray}
```
\

In order to capture the expected influence of co-ancestry on $\mathbf{y}$, (similar values among closely related taxa), the distribution of our random effect, $\mathbf{b}$, is multivariate normal, with mean 0 and (co)variance given by $\sigma^2_{b}C$,

\

\begin{eqnarray}
\mathbf{b} &\sim& \mbox{MVN}(0, \sigma^2_{b}C)\\
\end{eqnarray}\

<!-- The phylogenetic variance (e.g., Brownian rate), $\sigma_{b}$, is a scalar to be estimated by the model and $A$ is a fixed $n\times n$ -->

<!-- phylogenetic VCV matrix, where $n$ is the number of taxa in the tree. This model therefore takes as input a phylogenetic tree (topology and branch lengths), which is assumed to be known without error. The $A$ matrix itself is derived by taking the inverse of the distance matrix of the tree. It gives the expected (co)variance among taxa in the value of $y$ assuming some model of evolution (e.g. BM) along the branches of that tree. -->

Here, $C$ is a fixed $n\times n$ phylogenetic covariance matrix, where $n$ is the number of taxa in the tree, and $\sigma^2_{b}$, the phylogenetic variance, is a scalar to be estimated by the model. This model therefore takes as input a phylogeny (topology and branch lengths), which is assumed to be known without error. The $C$ matrix is derived from the similarity matrix of the phylogeny. This gives the expected (co)variance among taxa in $\mathbf{y}$ assuming Brownian motion evolution [@symonds2014primer].

\

\begin{eqnarray}
C &=& 
\begin{pmatrix}C_{11} & C_{12} & \ldots & C_{1n} \\ 
                C_{21} & C_{22} & \ldots & C_{2n} \\
                \vdots & \vdots & \ddots & \vdots \\ 
                C_{n1} & C_{n2} & \ldots & C_{nn} \\ 
\end{pmatrix}
\end{eqnarray}\

In contrast, the identity matrix $I$ (an $n\times n$ matrix with 1 in all diagonal elements and 0 in all off-diagonal elements) encodes independent residual error associated with each observation (here, each taxon) in the distributional statement for the errors:

\

\begin{eqnarray}
\mathbf{e} &\sim& \mbox{MVN}(0, \sigma^2_{e}I)\\
\end{eqnarray}\

\

$\mathbf{EXAMPLE}$

Consider the following 5-taxon phylogeny with similarity between taxa shown on the x axis:

```{r, fig.width=5, fig.align='center'}
toy.phy <- read.tree(text='((5:3, (4:2, 3:2):1):1, (2:1, 1:1):3);')
plot(toy.phy, label.offset=0.1, edge.width=1.5)
axis(1, at = seq(0,4,by=1), labels = seq(0,4,by=1), line = 0.5)
title(xlab="similarity")
```

For this phylogeny, the similarity matrix (elements expressing the sum of shared branch lengths between two taxa, $i$ and $j$), $C$, is:

\

\begin{eqnarray}
C &=& 
\begin{pmatrix}C_{11} & C_{12} & C_{13} & C_{14} & C_{15} \\ 
                C_{21} & C_{22} & C_{23} & C_{24} & C_{25} \\
                C_{31} & C_{32} & C_{33} & C_{34} & C_{35} \\
                C_{41} & C_{42} & C_{43} & C_{44} & C_{45} \\
                C_{51} & C_{52} & C_{53} & C_{54} & C_{55} \\
                \end{pmatrix}
&=&                
\begin{pmatrix} 4 & 3 & 0 & 0 & 0 \\ 
                3 & 4 & 0 & 0 & 0 \\
                0 & 0 & 4 & 1 & 1 \\
                0 & 0 & 1 & 4 & 2 \\
                0 & 0 & 1 & 2 & 4 \\
                \end{pmatrix}

                
\end{eqnarray}\

In order to facilitate comparison between phylogenetic and independent contributions when partitioning the variance, $C$ is often standardised to the unit diagonal (i.e., re-scaled to a correlation matrix) prior to analyses, such that,

\

\begin{eqnarray}
C_{cor} &=& 
\begin{pmatrix} 1 & 0.75 & 0 & 0 & 0 \\ 
                0.75 & 1 & 0 & 0 & 0 \\
                0 & 0 & 1 & 0.25 & 0.25 \\
                0 & 0 & 0.25 & 1 & 0.5 \\
                0 & 0 & 0.25 & 0.5 & 1 \\
                \end{pmatrix}
\end{eqnarray}\

The identity matrix $I$ for this model is:

\begin{eqnarray}
I &=& 
\begin{pmatrix} 1 & 0 & 0 & 0 & 0 \\ 
                0 & 1 & 0 & 0 & 0 \\
                0 & 0 & 1 & 0 & 0 \\
                0 & 0 & 0 & 1 & 0 \\
                0 & 0 & 0 & 0 & 1 \\
                \end{pmatrix}
\end{eqnarray}\

\

## Data Simulation

Implementing these models in R is fairly straight forward in both MCMCglmm and brms. But first, let's simulate some data. To simulate data under this model, we simply construct our variable, $\mathbf{y}$, from the linear combination of predictors specified by the model, by supplying vectors of length $n$ for each of the quantities $\boldsymbol{\mu}$, $\mathbf{b}$, and $\mathbf{e}$. For Gaussian variables this can be done directly. For non-Gaussian variables simulation is a two-step process where $\mathbf{b}$ and $\mathbf{e}$ are simulated on the link scale to determine the mean and the response values themselves are subsequently drawn from the appropriate distribution (see section 3). In this example, we will simulate from an intercept only model ($\boldsymbol{\mu}$ = $\beta_0$).


```{r eval=T}

## SIMULATE FROM PMM

# simulate tree
n = 250 # number of species
phy <- geiger::sim.bdtree(b=1, d=0, stop="taxa", n=n, extinct=FALSE)

# create covariance matrix from tree, scale to correlation matrix with corr = T
C = ape::vcv.phylo(phy, corr = T)

# identity matrix
I = diag(n)

# fixed effects (intercept only)
u = 0

# phylogenetic variance
sigma_b = 1

# residual variance
sigma_e = 0.1

# simulate phylogenetic random effects as one draw from a MVN
b = MASS::mvrnorm(1,rep(0,n),sigma_b*C)

# simulate residuals
e = MASS::mvrnorm(1,rep(0,n),sigma_e*I)

# construct response from the linear predictor
y = u + b + e

# generate df
animal <- phy$tip.label # "animal" is a reserved term in MCMCglmm for taxon ID
d <- data.frame(animal,y)

```


We can plot our simulated data against the tree for a visual assessment of phylogenetic structure in the distribution of trait values

```{r, eval=T}
# convert to tibble and define 'id' column to associate data and tree in geom_facet
y_bar <- tibble(id = d$animal, bar_val = d$y)
# plot
ggtree(phy) + 
  geom_facet(panel = "trait", data = y_bar, geom = geom_col, 
             aes(x = bar_val), orientation = 'y', width = 1) + 
  theme(strip.background = element_blank(),strip.text = element_blank())

```


\

## Model Specification

With our tree and trait data simulated, we can now fit the model:


```{r eval=FALSE}

## MCMCglmm 
p.m.1 <- list(G = list(G1 = list(V = 1, nu = 0.002)), 
              R = list(V = 1, nu = 0.002))
m.1 <- MCMCglmm(y ~ 1,
                random   = ~animal,
                pedigree = phy, 
                family   = c("gaussian"), 
                data     = d, 
                prior    = p.m.1,
                nitt     = 110000, 
                burnin   = 10000, 
                thin     = 100,
                pr = T, verbose = F
                )


## BRMS
p.b.1 <- set_prior("student_t(3, 0, 2.5)", class = c("sd","sigma","Intercept"), lb = c(0,0,NA))
b.1 <- brm(y ~ 1 + (1|gr(animal, cov = C)), 
           data   = d,
           prior  = p.b.1,
           family = gaussian(), 
           data2  = list(C = C),
           cores  = 4, 
           chains = 4
           )

```

\

## Model Syntax

The code above fits the same model in MCMCglmm and brms. In MCMCglmm, `animal` is a reserved term used to identify individuals/taxa in a quantitative genetic/phylogenetic analysis. The random effect specification `~animal` instructs MCMCglmm to fit a random effect at the individual/taxon level with covariance structure supplied via the `pedigree` argument. For `pedigree`, MCMCglmm accepts a `phylo` object directly and performs the necessary steps to derive the matrix $C$ under the hood. The remaining arguments specify the data, the priors, and the sampler settings. The argument `pr` is used to retain the posterior distribution of random effects.

In brms, the phylogenetic random effect can be encoded in the style of lme4 `(1|gr(animal, cov = C))`, where `(1|x)` specifies random intercepts and `gr(animal, cov = C)` encodes the phylogenetic group structure.

It is not necessary to specify a prior to fit this model in either MCMCglmm or brms because sensible defaults are used automatically. However, we choose to explicitly specify (current default) priors to ensure repeatability, should the defaults change in the future. A key difference between these packages is the Monte Carlo sampling method implemented and the subsequent choice of priors. MCMCglmm is based on Gibbs sampling, which utilises conjugate prior distributions to reduce sampling time through analytic computations. brms uses Hamiltonian Monte Carlo sampling which is an efficient hybrid of optimisation and sampling approaches that places no restrictions on the choice of prior.

\

## Convergence Diagnostics

Basic convergence diagnostics are easily obtained for each package. As a first step, it is advisable to perform visual checks of the MCMC sample trace to confirm adequate mixing and stationary chains.

```{r, eval = F}

# visual check for convergence in MCMC chains
plot(m.1$VCV)
plot(b.1)

```

Another standard indicator of sampling adequacy is the effective sample size (ESS) of each parameter estimate. In the presence of auto-correlation between MCMC samples, the ESS will be reduced relative to the thinned sample number, with low ESS indicating poor sampling. ESS is reported in the model summary for both MCMCglmm and brms.

```{r, eval = F}

# model summaries
summary(m.1)
b.1

```

We can also check the autocorrelation in MCMC draws generated by the Gibbs sampler in MCMCglmm. Ideally, we want to see values close to 0 for all rows below "Lag 0", which would signify negligible autocorreation at the thinning interval chosen during model fit [@de2018quantitative]. These diagnostics are generally not necessary for models fit in brms, as the Hamiltonian sampler ensures minimal autocorrelation between samples.

```{r, eval = F}

# calculate autocorrelation in MCMC draws
autocorr(m.1$VCV)

```

As brms fits multiple MCMC chains by default, potential scale reduction factors, $\widehat{R}$, are reported in the model summary for a quantitative assessment of convergence for each parameter. As a rule of thumb, $\widehat{R}$ $\\<$ 1.05 indicate adequate convergence [@gelman2013BDA]. For MCMCglmm, $\widehat{R}$ can be calculated from multiple MCMC chains of the same model using the `Rhat` function from rstan.

```{r, eval = F}

# calculate potential scale reduction factors for each 
# variance component over multiple (4) MCMC chains
m.1.2 <- mclapply(1:4, function(i) {
  MCMCglmm(y ~ 1,
           random   = ~animal,
           pedigree = phy, 
           family   = c("gaussian"), 
           data     = d, 
           prior    = p.m.1,
           nitt     = 110000,
           burnin   = 10000, 
           thin     = 100,
           pr = T, verbose = F
           )
}, mc.cores=1)
m.1.2 <- lapply(m.1.2, function(m) m$VCV)
m.1.2 <- do.call(mcmc.list, m.1.2)
plot(m.1.2)

# units
units <- lapply(m.1.2, "[", , "units")
units <-  tibble("c1" = units[[1]],"c2" = units[[2]],"c3" = units[[3]],"c4" = units[[4]])
units %>% as.matrix %>% Rhat
# animal
animal <- lapply(m.1.2, "[", , "animal")
animal <-  tibble("c1" = animal[[1]],"c2" = animal[[2]],"c3" = animal[[3]],"c4" = animal[[4]])
animal %>% as.matrix %>% Rhat


```

\

## Model Validation

Having satisfied convergence diagnostics, the next step is to evaluate model performance through validation procedures such as posterior predictive checks. Posterior predictive checks simulate data under the fitted model, then compare these replicated data sets (or appropriate summary statistics) to the observed data to identify any systematic discrepancies (@gelman2006data, p. 158). It is very straightforward to run posterior predictive checks in brms.

```{r, eval = F}

# posterior predictive checks
b.1 %>% pp_check(ndraws = 100)


```

For MCMCglmm, posterior predictive checks are also obtained fairly easily (see [@hadfield2010] and MCMCglmm course notes).

```{r, eval = F}

# posterior predictive checks
rep <- 100
pred <- matrix(nrow = rep, ncol = n) # ncol = number of taxa
for (i in 1:rep) {
pred[i,] <- rnorm(n, (m.1$X %*% m.1$Sol[i,])@x, sqrt(sum(m.1$VCV[i,])))
}
obs <- d$y
pp_check(obs, pred, ppc_dens_overlay)


```

However, an even more rigorous and sophisticated approach to model validation of MR-PMM is leave-one-out (LOO) cross-validation (CV) (@roberts2017cross; also see section 5 on Prediction in manuscript). Cross validation is the use of data splitting to estimate the predictive performance of one or more statistical models, usually for the purpose of model comparison and selection. However, predictive assessment tools such as cross validation are also useful to quantify or simply visualise how well a model can predict to new data (out of sample performance), e.g., to new taxon-trait pairs in a PMM. This is distinct from the assessment of model adequacy which concerns prediction of data to which a model was fit (within sample performance).

\

## Inference

Having fit and validated our model, the next step is to make inferences on the parameters estimated. In the Bayesian paradigm, inference is based upon summary statistics of the posterior distributions of the model parameters. For example, hypothesis tests can be performed by evaluating whether a credible interval (e.g. 95%) of the posterior of a parameter crosses zero. This is easily evaluated from the model summary. However, we note that, while intercept estimates are directly comparable, MCMCglmm reports variance components where-as brms reports these quantities as standard deviations. As our simulations also specify variances, we will re-scale estimates from brms by calculating quantiles from the square of MCMC samples.

```{r, eval = F}
# summary
summary(m.1)
summary(b.1)

# intercept
summary(m.1)$solutions
summary(b.1)[["fixed"]]

# phylogenetic variance (sigma_b)
m.1$VCV[,"animal"] %>% quantile(probs=c(0.025,0.5,0.975))
b.1 %>% as_tibble() %>% 
  pull(sd_animal__Intercept) %>% .^2 %>% as.mcmc %>% quantile(probs=c(0.025,0.5,0.975))

# residual variance (sigma_e)
m.1$VCV[,"units"] %>% quantile(probs=c(0.025,0.5,0.975))
b.1 %>% as_tibble() %>% 
  pull(sigma) %>% .^2 %>% as.mcmc %>% quantile(probs=c(0.025,0.5,0.975))

```

\

### Phylogenetic Signal

An estimate of phylogenetic signal (the proportion of variation in a trait attributed to phylogenetic effects) in $\mathbf{y}$ can be calculated as

\begin{eqnarray} \label{eq_h2}
h^2 = \sigma^2_{b}/(\sigma^2_{b}+\sigma^2_{e})
\end{eqnarray}\

```{r, eval = F}

# MCMCglmm
(m.1$VCV[,"animal"]/(m.1$VCV[,"animal"]+m.1$VCV[,"units"])) %>% quantile(probs=c(0.025,0.5,0.975))

# brms
b.1 %>% as_tibble() %>% 
        dplyr::select(sigma_b = sd_animal__Intercept, sigma_e = sigma) %>% 
        mutate(h2 = sigma_b^2/(sigma_b^2 + sigma_e^2)) %>% 
        pull(h2) %>% quantile(probs=c(0.025,0.5,0.975))

```

We can also confirm that $h^2$ from our PMM is estimating the same quantity as the MLE of lambda from an equivalent pgls model.

```{r, eval = F}

## compare to MLE of lambda from PGLS
comp_dat <- comparative.data(phy, d, animal, vcv=TRUE)
mod <- pgls(y ~ 1, data = comp_dat, lambda = "ML")
summary(mod)$param["lambda"]

```

\

# Model 2 - Multi-Response Gaussian

\

## Model Explanation

For multi-response (MR) models, response variables are modelled jointly, allowing both phylogenetic and independent (co)variances to be estimated. A MR-PMM with two Gaussian response variables takes the form,

\

```{=tex}
\begin{eqnarray}
\begin{pmatrix}\mathbf{y}_1 \\
\mathbf{y}_2 \end{pmatrix} &=& 
\begin{pmatrix}\boldsymbol{\mu}_1 + \mathbf{b}_1 + \mathbf{e}_1 \\
               \boldsymbol{\mu}_2 + \mathbf{b}_2 + \mathbf{e}_2
\end{pmatrix}\\
\end{eqnarray}
```
\

where fixed effects are expressed as a linear combination of predictors,

\

```{=tex}
\begin{eqnarray}
\begin{pmatrix}\boldsymbol{\mu}_1 \\ \boldsymbol{\mu}_2 \end{pmatrix} &=& 
\begin{pmatrix}\beta_{0,1}\mathbf{1} + \beta_{1,1}\boldsymbol{X_{1,1}} + \ldots + \beta_{k,1}\boldsymbol{X_{k,1}} \\
               \beta_{0,2}\mathbf{1} + \beta_{1,2}\boldsymbol{X_{1,2}} + \ldots + \beta_{k,2}\boldsymbol{X_{k,2}}
\end{pmatrix}\\
\end{eqnarray}
```
\

With this design, the phylogenetic random effects are also realised jointly as a multivariate normal, with variance given by $\Sigma^{\mathrm{phy}} \otimes C$, the Kronecker product of a trait-level covariance matrix $\Sigma^{\mathrm{phy}}$ and the fixed phylogenetic covariance matrix, $C$. With $m$ traits (response variables), $\Sigma^{\mathrm{phy}}$ is m x m and specifies the phylogenetic variance in each trait (diagonals) as well as the phylogenetic covariance between traits (off-diagonals). With $n$ taxa in the phylogeny, $\Sigma^{\mathrm{phy}} \otimes C$ is an $mn\times mn$ cross-covariance matrix containing phylogenetic (co)variances for all traits as well as between all traits. Thus, the phylogenetic random effects and independent residuals are drawn from multivariate normal distributions,

\

\begin{eqnarray}
\begin{pmatrix}\mathbf{b}_1 , \mathbf{b}_2 \\ \end{pmatrix}^\mathrm{T} &\sim& \mbox{MVN}(0, \Sigma^{\mathrm{phy}} \otimes C)\\
\begin{pmatrix}\mathbf{e}_1 , \mathbf{e}_2 \\ \end{pmatrix}^\mathrm{T} &\sim& \mbox{MVN}(0, \Sigma^{\mathrm{ind}} \otimes I)\\[2mm]

\Sigma &=& \Sigma^{\mathrm{phy}} \otimes C + \Sigma^{\mathrm{ind}} \otimes I
\end{eqnarray}\

Notice that the two taxon-level variance structures we encountered in the univariate case above ($C$ and $I$) remain, but we must now also consider trait-level covariance (i.e., the tendency for response traits to covary) operating at both the phylogenetic and independent level. This is achieved via the Kronecker operation $\otimes$ (see matrix expansions below). The phylogenetic trait-level VCV matrix $\Sigma^{\mathrm{phy}}$ is $m\times m$, where $m$ is the number of response traits in the model,

\

\begin{eqnarray}
\Sigma^{\mathrm{phy}}
= 
\begin{pmatrix}\Sigma^{\mathrm{phy}}_{11} & \Sigma^{\mathrm{phy}}_{12} & \ldots & \Sigma^{\mathrm{phy}}_{1m} \\ 
                \Sigma^{\mathrm{phy}}_{21} & \Sigma^{\mathrm{phy}}_{22} & \ldots & \Sigma^{\mathrm{phy}}_{2m} \\
                \vdots & \vdots & \ddots & \vdots \\ 
                \Sigma^{\mathrm{phy}}_{m1} & \Sigma^{\mathrm{phy}}_{m2} & \ldots & \Sigma^{\mathrm{phy}}_{mm} \\ \end{pmatrix}
&=& 
\begin{pmatrix}(\sigma^{\mathrm{{phy}}}_1)^2 &
                \sigma^{\mathrm{{phy}}}_1\sigma^{\mathrm{{phy}}}_2\rho^{\mathrm{{phy}}}_{12} & 
                \ldots & 
                \sigma^{\mathrm{{phy}}}_1\sigma^{\mathrm{{phy}}}_m\rho^{\mathrm{{phy}}}_{1m} \\ 
                \sigma^{\mathrm{{phy}}}_2\sigma^{\mathrm{{phy}}}_1\rho^{\mathrm{{phy}}}_{21} & 
                (\sigma^{\mathrm{phy}}_2)^2 & 
                \ldots & 
                \sigma^{\mathrm{{phy}}}_2\sigma^{\mathrm{{phy}}}_m\rho^{\mathrm{{phy}}}_{2m} \\
                \vdots & \vdots & \ddots & \vdots \\ 
                \sigma^{\mathrm{{phy}}}_m\sigma^{\mathrm{{phy}}}_1\rho^{\mathrm{{phy}}}_{m1} & 
                \sigma^{\mathrm{{phy}}}_m\sigma^{\mathrm{{phy}}}_2\rho^{\mathrm{{phy}}}_{m2} &
                \ldots & 
                (\sigma^{\mathrm{phy}}_m)^2 \\ \end{pmatrix}\\[2mm]

\end{eqnarray}\

such that elements of $\Sigma^{\mathrm{phy}}$ have the general form,

\

```{=tex}
\begin{eqnarray}
\Sigma^{\mathrm{{phy}}}_{ij} = \sigma^{\mathrm{{phy}}}_i\sigma^{\mathrm{{phy}}}_j\rho^{\mathrm{{phy}}}_{ij} \\
\end{eqnarray}
```
\

where $\rho^{\mathrm{{phy}}}_{ij}$ is the phylogenetic correlation between traits $i$ and $j$ and $\sigma^{\mathrm{{phy}}}_i$ is the standard deviation of the phylogenetic component of variation in trait $i$. Thus, returning to our 5-taxon example, a MR model with two Gaussian response traits (i.e., $m = 2$) will have covariance matrix for the phylogenetic random effects, $\Sigma^{\mathrm{phy}} \otimes C$, of the form:

\

<!-- Can't get parenthesis  around smallmatrix. Need \mathtools but how to load?  -->

\begin{eqnarray}

\Sigma^{\mathrm{phy}} \otimes C
&=& 
\begin{pmatrix} \Sigma^{\mathrm{phy}}_{11}C & \Sigma^{\mathrm{phy}}_{12}C  \\ 
                \Sigma^{\mathrm{phy}}_{21}C & \Sigma^{\mathrm{phy}}_{22}C  \\
\end{pmatrix}
&=&
\begin{pmatrix} \Sigma^{\mathrm{phy}}_{11}
                \left(\begin{smallmatrix} 
                4 & 3 & 0 & 0 & 0 \\ 
                3 & 4 & 0 & 0 & 0 \\
                0 & 0 & 4 & 1 & 1 \\
                0 & 0 & 1 & 4 & 2 \\
                0 & 0 & 1 & 2 & 4 \\
                \end{smallmatrix}\right) &
                \Sigma^{\mathrm{phy}}_{12}
                \left(\begin{smallmatrix} 
                4 & 3 & 0 & 0 & 0 \\ 
                3 & 4 & 0 & 0 & 0 \\
                0 & 0 & 4 & 1 & 1 \\
                0 & 0 & 1 & 4 & 2 \\
                0 & 0 & 1 & 2 & 4 \\
                \end{smallmatrix}\right) \\
                \Sigma^{\mathrm{phy}}_{21}
                \left(\begin{smallmatrix} 
                4 & 3 & 0 & 0 & 0 \\ 
                3 & 4 & 0 & 0 & 0 \\
                0 & 0 & 4 & 1 & 1 \\
                0 & 0 & 1 & 4 & 2 \\
                0 & 0 & 1 & 2 & 4 \\
                \end{smallmatrix}\right) &
                \Sigma^{\mathrm{phy}}_{22}
                \left(\begin{smallmatrix} 
                4 & 3 & 0 & 0 & 0 \\ 
                3 & 4 & 0 & 0 & 0 \\
                0 & 0 & 4 & 1 & 1 \\
                0 & 0 & 1 & 4 & 2 \\
                0 & 0 & 1 & 2 & 4 \\
                \end{smallmatrix}\right)\\
\end{pmatrix}

\end{eqnarray}\

\

Similarly, the covariance matrix for the independent residual errors, $\Sigma^{\mathrm{ind}} \otimes I$, is:

\

<!-- Can't get parenthesis  around smallmatrix. Need \mathtools but how to load?  -->

\begin{eqnarray}

\Sigma^{\mathrm{ind}} \otimes I
&=& 
\begin{pmatrix} \Sigma^{\mathrm{ind}}_{11}I & \Sigma^{\mathrm{ind}}_{12}I  \\ 
                \Sigma^{\mathrm{ind}}_{21}I & \Sigma^{\mathrm{ind}}_{22}I  \\
\end{pmatrix}
&=&
\begin{pmatrix} \Sigma^{\mathrm{ind}}_{11}
                \left(\begin{smallmatrix} 
                1 & 0 & 0 & 0 & 0 \\ 
                0 & 1 & 0 & 0 & 0 \\
                0 & 0 & 1 & 0 & 0 \\
                0 & 0 & 0 & 1 & 0 \\
                0 & 0 & 0 & 0 & 1 \\
                \end{smallmatrix}\right) &
                \Sigma^{\mathrm{ind}}_{12}
                \left(\begin{smallmatrix} 
                1 & 0 & 0 & 0 & 0 \\ 
                0 & 1 & 0 & 0 & 0 \\
                0 & 0 & 1 & 0 & 0 \\
                0 & 0 & 0 & 1 & 0 \\
                0 & 0 & 0 & 0 & 1 \\
                \end{smallmatrix}\right)\\
                \Sigma^{\mathrm{ind}}_{21}
                \left(\begin{smallmatrix} 
                1 & 0 & 0 & 0 & 0 \\ 
                0 & 1 & 0 & 0 & 0 \\
                0 & 0 & 1 & 0 & 0 \\
                0 & 0 & 0 & 1 & 0 \\
                0 & 0 & 0 & 0 & 1 \\
                \end{smallmatrix}\right)&
                \Sigma^{\mathrm{ind}}_{22}
                \left(\begin{smallmatrix} 
                1 & 0 & 0 & 0 & 0 \\ 
                0 & 1 & 0 & 0 & 0 \\
                0 & 0 & 1 & 0 & 0 \\
                0 & 0 & 0 & 1 & 0 \\
                0 & 0 & 0 & 0 & 1 \\
                \end{smallmatrix}\right)\\
\end{pmatrix}

\end{eqnarray}\

**N.B. This example is purely for illustrative purposes. The parameters of this model are not estimable with such low phylogenetic replication (n = 5 taxa).** Low dimensional $A$ and $I$ are used here simply to show the working of matrix manipulations.

\

## Data Simulation

With multiple response variables, we must now consider covariance between responses at both the phylogenetic and independent level. To incorporate this into our data simulations, we must specify the relevant (co)variance structures for our random effects and independent errors.

```{r eval=FALSE}

## SIMULATE FROM MR-PMM

# number of traits
m = 2

# fixed effects (intercepts for each trait)
u = c(0,0)

# construct the phylogenetic trait-level covariance matrix, Sigma_phy
sig.b <- c(b11 = 1, b22 = 1) # sqrt of phylogenetic variance for each trait; set to 1 so sigma = sigma^2
cor.b.12 = 0.5 # phylogenetic correlation between traits 1 and 2
Bcor <- matrix(c(c(1,cor.b.12), c(cor.b.12,1)),m,m, byrow = T) # phylogenetic correlation matrix
Sigma_phy <- matrix(kronecker(sig.b, sig.b),m,m)*Bcor # construct Sigma_phy as point-wise product

# N.B. Kronecker used here just for ease of matrix formatting. Do not confuse with Kronecker operation used below for generating the cross-covariance matrices for the random effects (eq. 8 in manuscript), i.e., kronecker(Sigma_phy,C). 

# construct the independent trait-level covariance matrix, Sigma_ind
sig.e <- c(e11 = 1, e22 = 1) # sqrt of independent variance for each trait
cor.e.12 = 0.5 # independent correlation
Ecor <- matrix(c(c(1,cor.e.12),c(cor.e.12,1)),m,m, byrow = T)  # independent correlation matrix
Sigma_ind <- matrix(kronecker(sig.e, sig.e),m,m)*Ecor # Construct Sigma_ind as point-wise product

# simulate phylogenetic random effects
# n = 1 in order to generate 1 random effect per taxon, mu = rep(0,n*m) centers random effects for all taxa on zero, Sigma = kronecker(Sigma_phy,C) defines the cross-covariance matrix of the random effects.
b = mvrnorm(n = 1, mu = rep(0,n*m), Sigma = kronecker(Sigma_phy,C))
# extract for each trait from the vector, b.
b1 <- b[1:n] # effects 1:n relate to trait 1
b2 <- b[(1:n) + n] # effects (1:n)+n relate to trait 2

# simulate errors and extract
# In the kronecker, (phylogeny) independent trait-level covariance captured by Sigma_ind, taxon-level independent error captured by I.
e = mvrnorm(1,rep(0,n*m),kronecker(Sigma_ind,I))
e1 <- e[1:n]
e2 <- e[(1:n) + n]

# construct response traits from each linear predictor
# i.e., for each trait, add b's and e's to the fixed effect u's
y1 = u[1] + b1 + e1
y2 = u[2] + b2 + e2

# generate data frame
animal <- phy$tip.label
d2 <- data.frame(animal,y1,y2)
d2$obs <- 1:nrow(d2)

```

\

## Model Specification

A MR-PMM with two Gaussian response traits can be specified in MCMCglmm and brms as follows:

```{r eval=FALSE}

## MCMCglmm 
p.m.2 <- list(G = list(G1 = list(V = diag(2), nu = 1.002)), 
              R = list(R1 = list(V = diag(2), nu = 1.002)))
m.2 <- MCMCglmm(cbind(y1, y2) ~ trait-1,
                random   = ~us(trait):animal,
                rcov     = ~us(trait):units,
                pedigree = phy,
                family   = c("gaussian","gaussian"), 
                data     = d2, 
                prior    = p.m.2, 
                nitt     = 110000, 
                burnin   = 10000, 
                thin     = 100,
                pr = T, verbose = F
                )

## brms
b.2.bf <- brmsformula(mvbind(y1, y2) ~ (1|b|gr(animal, cov = C))) + set_rescor(TRUE)
p.b.2 <- set_prior(prior = rep(c("student_t(3, 0, 2.5)","student_t(3, 0, 2.5)", "student_t(3, 0.9, 2.5)"),2),
                   class = rep(c("sd","sigma","Intercept"),2), 
                   lb = rep(c(0,0,NA)), resp = rep(c("y1","y2"), each = 3))
b.2 <- brm(b.2.bf,
           data   = d2,
           prior  = p.b.2,
           family = gaussian(), 
           data2  = list(C = C),
           cores  = 4, 
           chains = 4
           )

```

\

## Model Syntax

In MCMCglmm, we use `cbind()` to specify multiple response variables. The reserved term `trait` is used to specify fixed effects for all response variables. In our example, `trait-1` suppresses the global intercept, instead fitting separate intercepts for each trait $y1$ and $y2$. With multiple response variables, it is now possible to model covariance between responses at different levels in the model hierarchy. MCMCglmm offers several options for defining the structure of covariance matrices to be estimated (@hadfield2010; also see MCMCglmm course notes). The argument `~us(trait)` specifies an unstructured (all elements estimated) covariance matrix with dimension equal to the number of response traits (here 2 x 2). The suffix `:animal` specifies this covariance matrix is on the level of the grouping factor `animal`, where-as `:units` encodes an independent (residual) covariance matrix.

In brms, we use `mvbind()` to specify multiple response variables. An index (here `|b|`, but any unique identifier is accepted) is used within the random effect specification to instruct brms to estimate the correlation between $y1$ and $y2$ at the animal group level. If omitted, only the correlation between $y1$ and $y2$ on the independent level will be estimated.

\

## Inference

### Correlations

For MR cases, the parameters of greatest interest are typically the phylogenetic and independent (co)variance components, which are used to derive correlations by substituting relevant elements into,

\begin{eqnarray} \label{eq_cor_PMM}
\rho^{\cdots}_{12} = \frac{\Sigma^{\cdots}_{12}}{\sqrt{(\Sigma^{\cdots}_{11} \times \Sigma^{\cdots}_{22})}}
\end{eqnarray}\

Thus, posterior distributions of each pairwise correlation estimate are obtained by supplying vectors of posterior samples for each (co)variance parameter. These calculations are performed and reported by default in the brms model summary. For MCMCglmm, correlations can be calculated from (co)variance estimates with some basic manipulations:

```{r eval=FALSE}

## brms
# phylogenetic correlation = cor(y1_Intercept,y2_Intercept)
# independent correlation = rescor(y1,y2)
summary(b.2)

## MCMCglmm
# phylogenetic correlation between y1 and y2
quantile(m.2$VCV[,"traity1:traity2.animal"]/
     sqrt(m.2$VCV[,"traity1:traity1.animal"]*m.2$VCV[,"traity2:traity2.animal"]))
# independent correlation between y1 and y2
quantile(m.2$VCV[,"traity1:traity2.units"]/
     sqrt(m.2$VCV[,"traity1:traity1.units"]*m.2$VCV[,"traity2:traity2.units"]))

```

\

### Partial Correlations

Due to the partitioning achieved in MR-PMM, the fitted covariance matrices $\Sigma^{\mathrm{phy}}$ and $\Sigma^{\mathrm{ind}}$ may be used to compute conditional dependencies (i.e., partial correlations) between traits on both the phylogenetic and independent level. These quantities describe the pairwise relationship between response traits after accounting for the effects of all other response traits specified in the model, and are thus analogous to the partial regression coefficients estimated in multiple regression. Partial correlations on the phylogenetic and independent level are derived by computing the matrix inverse (known as the precision matrix for covariance matrices) of $\Sigma^{\mathrm{phy}}$ and $\Sigma^{\mathrm{ind}}$, respectively. The off-diagonal elements of the resulting precision matrices are then used to compute partial correlations:

TO BE CONTINUED...



\

### Phylogenetic Signal

Phylogenetic signal is calculated for each trait by substituting elements of the parameterized (co)variance matrices $\Sigma^{\mathrm{phy}}$ and $\Sigma^{\mathrm{ind}}$ into the calculation of $h^2$, e.g., for $y1$:

```{r, eval = F}

# MCMCglmm
quantile(m.2$VCV[,"traity1:traity1.animal"]/
(m.2$VCV[,"traity1:traity1.animal"]+m.2$VCV[,"traity1:traity1.units"]))

# brms
b.2 %>% as_tibble() %>% 
        dplyr::select(sigma_b_y1 = sd_animal__y1_Intercept, sigma_e_y1 = sigma_y1) %>% 
        mutate(h2_y1 = sigma_b_y1^2/(sigma_b_y1^2 + sigma_e_y1^2)) %>% 
        pull(h2_y1) %>% quantile(probs=c(0,0.25,0.5,0.75,1))

```

\

# Model 3 - Multi-Response Non-Gaussian (Gaussian, Bernoulli)

\

## Model Explanation

In previous simulations, we saw that Gaussian responses can be drawn directly from the multivariate structure, i.e., modeled via the identity link function. For non-Gaussian variables, (co)variances must be modeled on the link scale. For example, for Poisson regression the mean is modeled with the log link while for binomial data, the probability of success is modeled with the logit link. To demonstrate this, we will again simulate and fit data under a bivariate model, this time taking a binomial response for $\mathbf{y_2}$.

\


\begin{eqnarray}
\begin{pmatrix}\mathbf{y_1} \\ \mathrm{logit}(\mathbf{p_2}) \end{pmatrix} &=& 
\begin{pmatrix}\boldsymbol{\mu}_1 + \mathbf{b}_1 + \mathbf{e}_1 \\
               \boldsymbol{\mu}_2 + \mathbf{b}_2 + \mathbf{e}_2 \\
\end{pmatrix}\\[2mm]
\\

\mathbf{y_2} &\sim& \mathrm{binomial}(\mathbf{p_2})

\end{eqnarray}

\

## Data Simulation

Using our vectors of random effects and residuals simulated previously (on the link scale), we can now simply use the inverse link function to realise $\mathbf{y_2}$ as a binomial variable.

```{r eval=FALSE}

## SIMULATE DATA

# construct response traits from each linear predictor
y1 = u[1] + b1 + e1 # gaussian
y2 = rbinom(n,1,plogis(u[2] + b2 + e2)) # binomial

# generate df
animal <- phy$tip.label
d3 <- data.frame(animal,y1,y2)
d3$obs <- 1:nrow(d3)

```

\

## Model Specification

Specification of this model changes very little for MCMCglmm; the second argument to `family` is simply specified as "categorical" (or alternatively, "threshold"; see MCMCglmm course notes). Prior specification requires more careful attention. For binomial variables, the residual variance is not identifiable. This is handled in MCMCglmm by fixing the residual variance of the binomial response to a nominal value (here, V = 1) in the prior specification [@hadfield2010]. Fixing at higher values of V can improve mixing of the chain, but may also lead to numerical problems. Importantly, it is still possible to estimate residual correlations between traits even when the residual variance is fixed (i.e., fixing the width of the error variance for our traits does not prevent correlation between joint multivariate draws), hence we still specify `rcov = ~us(trait):units` in the code below (also see `~corg()` in MCMCglmm course notes). We also implement parameter expanded priors for the random effects, which are recommended for "threshold" models (for details see @de2018quantitative and associated tutorial).

For brms, it is useful to specify separate formulae for each response variable when considering different error families. Unlike MCMCglmm, brms does not model additive overdispersion by default for non-gaussian traits. Thus, in order to model independent (co)variances, it is necessary to specify an additive overdispersion term in the form of an observation level random effect, `(1|e|obs)`. However, this introduces an identifiability issue for the Gaussian error term, which cannot be silenced with default brms coding. Here, for simplicity, we have just constrained the Gaussian error term to be small (`sigma = 0.1`). A more appropriate (albeit technically demanding) solution is to edit the underlying stan code to prevent estimation of the redundant Gaussian error term (see below).

```{r eval=FALSE}

# MCMCglmm
p3 <- list(G = list(G1 = list(V = diag(2), nu = 2, alpha.mu = rep(0,2), alpha.V = diag(2))), # parameter expanded prior for random effects of threshold response
           R = list(R1 = list(V = diag(2), nu = 2, fix = 2)))
m.3 <- MCMCglmm(cbind(y1, y2) ~ trait-1,
                random   = ~us(trait):animal,
                rcov     = ~us(trait):units,
                pedigree = phy,
                family   = c("gaussian", "categorical"), 
                data     = d3, 
                prior    = p3, 
                nitt     = 110000, 
                burnin   = 10000, 
                thin     = 100,
                pr=T, verbose = F
                )

# brms
bf_y1 <- brmsformula(y1 ~ 1 + (1|b|gr(animal, cov = C)) + (1|e|obs), sigma = 0.1) + gaussian()
bf_y2 <- brmsformula(y2 ~ 1 + (1|b|gr(animal, cov = C)) + (1|e|obs)) + bernoulli()
p.b.3 <- prior(student_t(3, 0, 2.5), class = "Intercept", resp = "y1", lb = NA) +
  prior(student_t(3, 0, 2.5), class = "Intercept", resp = "y2", lb = NA) +
  prior(student_t(3, 0, 2.5), class = "sd", resp = "y1", lb = 0) +
  prior(student_t(3, 0, 2.5), class = "sd", resp = "y2", lb = 0) +
  prior(constant(1), class = "sd", resp = "y2", group = "obs", lb = 0)
b.3 <- brm(bf_y1 + bf_y2 + set_rescor(FALSE),
          data   = d3, 
          family = gaussian(), 
          data2  = list(C = C),
          prior  = p.b.3,
          cores  = 4, 
          chains = 4
          )

```

\

## Inference

### Correlations

For MR models including non-Gaussian traits, the calculation of correlations between traits on the phylogenetic and independent level is unchanged so long as calculations are performed on the link scale (see Box 1 in manuscript).

### Phylogenetic Signal

An important consequence of fixing the residual variance for our Bernoulli trait $\mathbf{y_2}$ is that $h^2$ is no longer an appropriate method for estimating phylogenetic signal. Specifically, for a binomial trait, the amount of variation explained by shared ancestry is estimated as


\begin{eqnarray}
h^2_{\mathrm{logit}} = \Sigma^{\mathrm{phy}}_{22}/(\Sigma^{\mathrm{phy}}_{22}+V+\pi^2/3)
\end{eqnarray}


where $V$ is the level of residual variance (additive over-dispersion) fixed in the prior specification (here, V = 1) and $\pi^2/3$ is the distribution specific variance term for the binomial distribution with logit link [see @nakagawa2013general for details].

```{r eval=FALSE}
# MCMCglmm
(m.3$VCV[, "traity2.1:traity2.1.animal"]/(m.3$VCV[, "traity2.1:traity2.1.animal"] + 1 + pi^2/3)) %>%
  quantile(probs=c(0.025,0.5,0.975))

# BRMS
b.3 %>% as_tibble() %>% 
        dplyr::select(Sigma_phy_22 = sd_animal__y2_Intercept) %>% 
        mutate(h2_logit_y2 = Sigma_phy_22^2/(Sigma_phy_22^2 + 1 + pi^2/3)) %>% 
        pull(h2_logit_y2) %>% quantile(probs=c(0.025,0.5,0.975))

```

\

N.B. Even when dealing exclusively with Gaussian traits, adjustments to the calculation of $h^2$ are sometimes necessary. For example, when fixed effect predictors feature in the model, the variance explained by the fixed effects must be included in the denominator of the $h^2$ calculation [@de2016general].

\

## Customizing models further using Stan

For `brms`, models are specified using familiar `lme4` style R syntax, while estimation is carried out using Stan programs that are automatically constructed and compiled by the call to `brm()` prior to fitting. Thus, `brms` provides a user-friendly interface for exploiting the computational advantages of Stan, at the expense of imposing limitations on model specification. Thankfully, such limitations can often be overcome by encoding the mode directly in Stan. The Stan code underlying our fitted model is stored within the model object, which provides a convenient starting point for any alternations we would like to make.

```{r}

b.3$model

```

One such limitation arises in the specification of multi-response models containing Gaussian and non-Gaussian response variables when only a single value per species per trait is available (i.e., the data represent species mean trait values). Specifically, the additive overdispersion and observation-level (i.e., residual) variance components for the Gaussian response are not identifiable, because species and observation identities coincide. Furthermore, the Gaussian error term cannot be silenced within `brms` functions, requiring the user to fix the error to a small nominal value (e.g., `sigma = 0.1`) to restore model identifiability. By editing the Stan code directly, it is possible to silence this extraneous parameter. Specifically, we seek to fit the model,


\begin{eqnarray}

\begin{pmatrix}\mathbf{y_1} \\ \boldsymbol{\mu_2} \end{pmatrix}
&\sim& N
\begin{pmatrix}\boldsymbol{\mu}_1 + \mathbf{b}_1 & \multirow{2}{*}{, $\Sigma^e \otimes I$} \\
               \boldsymbol{\mu}_2 + \mathbf{b}_2 \\
\end{pmatrix}\\
\\
\begin{pmatrix}\mathbf{b_1} \\ \boldsymbol{b_2} \end{pmatrix} 
&\sim& N(0, \Sigma^b \otimes C) \\
\\
\mathbf{y_2} &\sim& \mathrm{bernoulli}(\eta, \mu_2)

\end{eqnarray}


which is achieved by making the following amendments to the Stan code

TO BE CONTINUED...


```{r, eval=F}

## TO DO
new_model

```


By revising the distributional statements for our observations, this approach also reduces the number of parameters to be estimated by the model (from X to Y), which reduces run time.


```{r, eval=F}

get_elapsed_time(new_model)

```




\

# Model 4 - Leaf Economics in Eucalyptus

\

We now present an example analysis using real data on leaf traits of Eucalyptus species from the AusTraits data set [@falster2021austraits]. Our intentions for this analysis were to evaluate evidence for: 1) phylogenetic signal in each trait; and 2) correlations between traits on the phylogenetic and independent level.

We derived the phylogenetic correlation matrix $C$ from the maximum likelihood Eucalypt phylogeny "ML1", presented in [@thornhill2019dated], pruning the tree to include only those species for which data was available (n = 316) for all three target leaf traits: specific leaf area (SLA); nitrogen content per dry mass of leaf tissue ($\mathbf{N}$); and the ratio of carbon isotopes 12 and 13 in leaf tissue ($\delta{13}{}{\mathbf{C}}$). We calculated species mean values and associated standard errors for each trait by pooling all observations at the species level. Where transformations to trait data were necessary, these were applied to individual observations, before means and standard errors were calculated, to avoid subsequent approximations of the standard error. Species for which the standard error of a trait could not be calculated because only a single observation was recorded were assigned a standard error equal to the 90th percentile of the standard error estimates for that trait across species. This represents a conservative approach to the assignment of unknown sampling variance in a meta-analytical context [@weir2018dealing;@ives2007within].

First, let's read in the tree and data.

```{r eval=TRUE}

euc_data <- read.csv("euc_data.csv")
euc_phy <- read.tree("euc_phy.tre")
C <- ape::vcv.phylo(euc_phy, corr = T)

```


For model fitting, we have set `max_treedepth = 12` based on warning messages issued when using default control settings.

```{r eval=FALSE}

# BRMS
bf_y1 <- brmsformula(log_SLA | resp_se(se_log_SLA, sigma = TRUE) ~ 1 + (1|b|gr(animal, cov = C))) 
bf_y2 <- brmsformula(N | resp_se(se_N, sigma = TRUE) ~ 1 + (1|b|gr(animal, cov = C))) 
bf_y3 <- brmsformula(d13C | resp_se(se_d13C, sigma = TRUE) ~ 1 + (1|b|gr(animal, cov = C))) 
b.euc <- brm(bf_y1 + bf_y2 + bf_y3 + set_rescor(TRUE),
            data      = euc_data, 
            family    = gaussian(), 
            data2     = list(C = C),
            control   = list(adapt_delta = 0.85, max_treedepth = 12),
            save_pars = save_pars(all = TRUE),
            cores     = 4, 
            chains    = 4
            )

```

```{r eval=TRUE, echo=F}

b.euc <- readRDS("b.euc.rds")

```


\

## Convergence Diagnostics

Next, we confirm that our model fit passes standard convergence diagnostics.

```{r, eval = FALSE}

# names of model parameters, excluding random effects and saved pars
pars <- b.euc %>% as_tibble %>% select(-starts_with(c("r_","z_","L_","Lres","lp"))) %>% names
# names of random effects
r_pars <- b.euc %>% as_tibble %>% select(starts_with("r_")) %>% names

# convergence diagnostics
mcmc_trace(b.euc, pars = pars)
mcmc_rhat(rhat(b.euc, pars = r_pars))
mcmc_neff(neff_ratio(b.euc, pars = r_pars))

rstan::check_hmc_diagnostics(b.euc$fit)

```

\

## Model Validation

We explore two approaches to model validation: 1) we assessed within-sample predictive capacity using marginal and conditional posterior predictive checks; and 2) we assessed out-of-sample predictive capacity using LOO-CV. 

For the first approach, posterior predictive checks verify the capacity of the model to generate plausible data; the proportion of data included in the nominal predictive intervals is generally close to expectation for each method and response trait.


```{r eval=T, message=F, fig.dim=c(6,6)}

#----------------------------
# posterior predictive checks
#----------------------------

# function to compute coverage
get_coverage <- function(data) data %>%
  transmute(cov90 = (hh >= y_obs) & (ll <= y_obs),
            cov50 = (h >= y_obs) & (l <= y_obs)) %>% 
  map_dbl(sum)

# CONDITIONAL
# i.e., prediction conditional on species-level random-intercept estimates
ppC1 <- pp_check(b.euc, resp= "logSLA", type = "intervals") + 
                labs(y = "log(SLA)", x = "")
ppC2 <- pp_check(b.euc, resp= "N", type = "intervals") + 
                labs(y = "N", x = "")
ppC3 <- pp_check(b.euc, resp= "d13C", type = "intervals") + 
                labs(y = bquote(delta^13*C), x = "taxon (index)")

covC1 <- ppC1$data %>% get_coverage() * 100/length(b.euc$data$animal); covC1 <- round(covC1)
covC2 <- ppC2$data %>% get_coverage() * 100/length(b.euc$data$animal); covC2 <- round(covC2)
covC3 <- ppC3$data %>% get_coverage() * 100/length(b.euc$data$animal); covC3 <- round(covC3)

# plot
ggarrange(ppC1 + labs(subtitle = paste0("Coverage: ", covC1[1], "% at 90th quantile, ",
                                       covC1[2],"% at 50th quantile")), 
          ppC2 + labs(subtitle = paste0("Coverage: ", covC2[1], "% at 90th quantile, ", 
                                       covC2[2],"% at 50th quantile")), 
          ppC3 + labs(subtitle = paste0("Coverage: ", covC3[1], "% at 90th quantile, ", 
                                       covC3[2],"% at 50th quantile")),
          nrow = 3, align = "hv", legend = "none") %>% 
  annotate_figure(top = "PP-checks: conditional on species-level random-intercept estimates")


# MARGINAL
# i.e., prediction marginalised over Gaussian distribution of random effects
ppM1 <- pp_check(b.euc, resp= "logSLA", type = "intervals", 
                allow_new_levels = T, sample_new_levels = "gaussian",
                newdata = b.euc$data %>% mutate(animal = NA)) + 
                labs(y = "log(SLA)", x = "")
ppM2 <- pp_check(b.euc, resp= "N", type = "intervals", 
                allow_new_levels = T, sample_new_levels = "gaussian",
                newdata = b.euc$data %>% mutate(animal = NA)) + 
                labs(y = "N", x = "")
ppM3 <- pp_check(b.euc, resp= "d13C", type = "intervals", 
                allow_new_levels = T, sample_new_levels = "gaussian", 
                newdata = b.euc$data %>% mutate(animal = NA)) + 
                labs(y = bquote(delta^13*C), x = "taxon (index)")

covM1 <- ppM1$data %>% get_coverage() * 100/length(b.euc$data$animal); covM1 <- round(covM1)
covM2 <- ppM2$data %>% get_coverage() * 100/length(b.euc$data$animal); covM2 <- round(covM2)
covM3 <- ppM3$data %>% get_coverage() * 100/length(b.euc$data$animal); covM3 <- round(covM3)

ggarrange(ppM1 + labs(subtitle = paste0("Coverage: ", covM1[1], "% at 90th quantile, ",
                                       covM1[2],"% at 50th quantile")), 
          ppM2 + labs(subtitle = paste0("Coverage: ", covM2[1], "% at 90th quantile, ", 
                                       covM2[2],"% at 50th quantile")), 
          ppM3 + labs(subtitle = paste0("Coverage: ", covM3[1], "% at 90th quantile, ", 
                                       covM3[2],"% at 50th quantile")),
          nrow = 3, align = "hv", legend = "none") %>%  
  annotate_figure(top = "PP-checks: marginalised over Gaussian distribution of random effects")


```

\

For LOO-CV, we find the approximate method [@burkner2021] fails for a reasonable proportion of the data, necessitating manual re-fits of the model. The computational demand of re-fitting such a large model for more than a few troublesome test data points is probably not feasible for the average desktop workstation. However, as HPC becomes more accessible to the average researcher, manual re-fitting procedures may represent a viable option to LOO-CV of MR-PMM.

```{r, eval = F, warning = F}

#----------------
# LOO predictions
#----------------

# perform LOO cross-validation in parallel using 'future' package
future::plan(future::multisession(workers = 6))
fit.loo <- loo(b.euc, moment_match = T, cores = 6, save_psis = T, reloo = F, future = T, future_args = list())
# saveRDS(fit.loo, "fit.loo.rds")

```

```{r, eval = T, echo = F}


fit.loo <-  readRDS("fit.loo.rds")

```

Compute LOO predictions, calculate coverage and plot.

```{r, eval = T, warning = F, fig.dim=c(6,6)}

# compute LOO predictions
loo_pred1 <- loo_predict(b.euc, resp = "logSLA", psis = fit.loo$psis_object, type = "quantile", probs = c(0.05,0.25,0.5,0.75,0.95))
loo_pred2 <- loo_predict(b.euc, resp = "N", psis = fit.loo$psis_object, type = "quantile", probs = c(0.05,0.25,0.5,0.75,0.95))
loo_pred3 <- loo_predict(b.euc, resp = "d13C", psis = fit.loo$psis_object, type = "quantile", probs = c(0.05,0.25,0.5,0.75,0.95))

# collate loo estimates
loo_pred_probs1 <- loo_pred1 %>% t %>% as.data.frame() %>% as_tibble()
loo_pred_probs2 <- loo_pred2 %>% t %>% as.data.frame() %>% as_tibble()
loo_pred_probs3 <- loo_pred3 %>% t %>% as.data.frame() %>% as_tibble()
colnames(loo_pred_probs1) <- colnames(loo_pred_probs2) <- colnames(loo_pred_probs3) <- c("ll","l","m","h","hh")

# compute coverage
cov1 <- loo_pred_probs1 %>% 
  mutate(x = 1:n(), k = fit.loo$diagnostics$pareto_k, y_obs = b.euc$data$log_SLA) %>% 
  get_coverage() * 100/length(b.euc$data$animal); cov1 <- round(cov1)
cov2 <- loo_pred_probs2 %>% 
  mutate(x = 1:n(), k = fit.loo$diagnostics$pareto_k, y_obs = b.euc$data$N) %>% 
  get_coverage() * 100/length(b.euc$data$animal); cov2 <- round(cov2)
cov3 <- loo_pred_probs3 %>% 
  mutate(x = 1:n(), k = fit.loo$diagnostics$pareto_k, y_obs = b.euc$data$d13C) %>% 
  get_coverage() * 100/length(b.euc$data$animal); cov3 <- round(cov3)

# define plot function
plot_loo_pred <- function(x,y_obs,cov,xlab,ylab) x %>%  
  mutate(y_obs = y_obs) %>% 
  arrange(m) %>% 
  mutate(x = 1:n()) %>% 
  ggplot(aes(x)) +
  geom_point(aes(y=m), size =3, col = blues9[4]) +
  geom_linerange(aes(ymin = ll, ymax = hh), col = blues9[4]) +
  geom_linerange(aes(ymin = l, ymax = h), linewidth = 1, col = blues9[4]) +
  geom_point(aes(y = y_obs)) +
  theme_classic() +
  labs(x = xlab, y = ylab, 
       subtitle = paste("Coverage: ", cov[1], "% at 90th quantile, ", cov[2],"% at 50th quantile"))

# plot
ggarrange(plot_loo_pred(loo_pred_probs1, b.euc$data$log_SLA, cov1, "", "logSLA"),
          plot_loo_pred(loo_pred_probs2, b.euc$data$N, cov2, "", "N"),
          plot_loo_pred(loo_pred_probs3, b.euc$data$d13C, cov3, "taxon (index)",bquote(delta^13*C)),
          ncol = 1, align = "hv") %>% 
  annotate_figure(top = "LOO predictive checks: out-of-sample predictive assessment")

```


\

## Inference

### Phylogenetic Signal

Our first aim was to assess phylogenetic signal ($h^2$) in our response traits:

``` {r, eval = T}

b.euc %>% as_tibble() %>% 
        dplyr::select(sigma_b_SLA = sd_animal__logSLA_Intercept, sigma_e_SLA = sigma_logSLA,
                      sigma_b_N = sd_animal__N_Intercept, sigma_e_N = sigma_N,
                      sigma_b_d13C = sd_animal__d13C_Intercept, sigma_e_d13C = sigma_d13C) %>% 
        mutate(h2_SLA = sigma_b_SLA^2/(sigma_b_SLA^2 + sigma_e_SLA^2),
               h2_N = sigma_b_N^2/(sigma_b_N^2 + sigma_e_N^2),
               h2_d13C = sigma_b_d13C^2/(sigma_b_d13C^2 + sigma_e_d13C^2)) %>% 
        dplyr::select(h2_SLA, h2_N, h2_d13C) %>% lapply(quantile, probs=c(0.025,0.5,0.975))

```

### Correlations

Our second aim was to assess correlations between response traits on the phylogenetic and independent level. Posterior means of parameter estimates (rho^{\mathrm{{phy}}}_{ij} and rho^{\mathrm{{ind}}}_{ij}) are reported in the model summary and visualised as 5-point summaries in the figure below.

``` {r, eval = T, warning = F}
b.euc

b.euc$fit %>%
  gather_draws(cor_animal__logSLA_Intercept__N_Intercept,
               cor_animal__logSLA_Intercept__d13C_Intercept,
               cor_animal__N_Intercept__d13C_Intercept,
               rescor__logSLA__N,
               rescor__logSLA__d13C,
               rescor__N__d13C) %>%
  median_hdi(.width = c(0.95, 0.5)) %>% 
  mutate(cor = rep(rep(c("N_mass ~ d13C","SLA ~ N_mass","SLA ~ d13C"),2),2)) %>% 
  mutate(level = rep(rep(c("phylogenetic","non-phylogenetic"),each=3),2)) %>%
  ggplot(aes(y = cor, x = .value, xmin = .lower, xmax = .upper, col = level)) +
  geom_pointinterval(position = position_dodge(width = 0.25),
                     interval_size_range = c(0.9, 2.1),
                     fatten_point = 1.8,) +
  geom_vline(xintercept = 0, col = "grey70", lty = "longdash") +
  theme_classic() + 
  theme(axis.text = element_text(size = 13),
        axis.title = element_text(size = 14),
        legend.text = element_text(size = 13),
        legend.title = element_text(size = 14),
        legend.key.size = unit(2, 'line')) +
  xlab("correlation estimate") + ylab("") + xlim(-1,1) +
  scale_color_manual(values = c("red", "#0072B2")) + 
  scale_y_discrete(labels=c("SLA ~ N_mass" = bquote(SLA~"~"~N[mass]),
                            "SLA ~ d13C" = bquote(SLA~"~"~delta^13*C),
                            "N_mass ~ d13C" = bquote(N[mass]~"~"~delta^13*C)))

```


\

## Notes

By using the consensus tree from [@thornhill2019dated] to compute $C$, we assume this phylogeny is known without error. In reality, phylogenies are inferred from sequence data with uncertainty, and thus represent mere hypotheses of the evolutionary relationships between taxa. Where-ever possible, it is preferable to propagate this uncertainty into our models. In a fully Bayesian setting, integrating over phylogenetic uncertainty is achieved by fitting models to a posterior sample of trees, e.g. with a function such as `brms_multiple`. When sequence data are available, an even more integrative approach is to infer phylogenies jointly with the estimation of trait correlations in the likelihood function (e.g. Cybis et al. 2016). We did not have access to a full posterior distribution of trees, though Thornhill et al. (2019) do present three alternative consensus trees; two inferred by ML and a third representing a consensus tree from a Bayesian analysis. Therefore, as an informal approach to test how sensitive results were to phylogenetic uncertainty, we fit the model to each tree separately and confirmed that each fit produced qualitatively equivalent parameter estimates (results not shown).

For discussion of the results of this analysis, see the manuscript at https://doi.org/10.1101/2022.12.13.520338.

\
\

# References
